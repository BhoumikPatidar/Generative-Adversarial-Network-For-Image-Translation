{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31435f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(image_shape):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tin_src_image = Input(shape=image_shape)\n",
    "\tin_target_image = Input(shape=image_shape)\n",
    "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
    "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = Activation('sigmoid')(d)\n",
    "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
    "\topt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=0.5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee36cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\tg = LeakyReLU(alpha=0.2)(g)\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48c625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\tg = BatchNormalization()(g, training=True)\n",
    "\tif dropout:\n",
    "\t\tg = Dropout(0.5)(g, training=True)\n",
    "\tg = Concatenate()([g, skip_in])\n",
    "\tg = Activation('relu')(g)\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ec1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(image_shape=(256,256,3)):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tin_image = Input(shape=image_shape)\n",
    "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "\te2 = define_encoder_block(e1, 128)\n",
    "\te3 = define_encoder_block(e2, 256)\n",
    "\te4 = define_encoder_block(e3, 512)\n",
    "\te5 = define_encoder_block(e4, 512)\n",
    "\te6 = define_encoder_block(e5, 512)\n",
    "\te7 = define_encoder_block(e6, 512)\n",
    "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "\tb = Activation('relu')(b)\n",
    "\td1 = decoder_block(b, e7, 512)\n",
    "\td2 = decoder_block(d1, e6, 512)\n",
    "\td3 = decoder_block(d2, e5, 512)\n",
    "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "\tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "\tout_image = Activation('tanh')(g)\n",
    "\tmodel = Model(in_image, out_image)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f650015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model, image_shape):\n",
    "\tfor layer in d_model.layers:\n",
    "\t\tif not isinstance(layer, BatchNormalization):\n",
    "\t\t\tlayer.trainable = False\n",
    "\tin_src = Input(shape=image_shape)\n",
    "\tgen_out = g_model(in_src)\n",
    "\tdis_out = d_model([in_src, gen_out])\n",
    "\tmodel = Model(in_src, [dis_out, gen_out])\n",
    "\topt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fabc6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples(filename):\n",
    "\tdata = load(filename)\n",
    "\tX1, X2 = data['arr_0'], data['arr_1']\n",
    "\tX1 = (X1 - 127.5) / 127.5\n",
    "\tX2 = (X2 - 127.5) / 127.5\n",
    "\treturn [X1, X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e9e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "\ttrainA, trainB = dataset\n",
    "\tix = randint(0, trainA.shape[0], n_samples)\n",
    "\tX1, X2 = trainA[ix], trainB[ix]\n",
    "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "\treturn [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5747cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "\tX = g_model.predict(samples)\n",
    "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ca09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, dataset, n_samples=3):\n",
    "\t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
    "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "\tX_realA = (X_realA + 1) / 2.0\n",
    "\tX_realB = (X_realB + 1) / 2.0\n",
    "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
    "\tfor i in range(n_samples):\n",
    "\t\tpyplot.subplot(3, n_samples, 1 + i)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(X_realA[i])\n",
    "\tfor i in range(n_samples):\n",
    "\t\tpyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(X_fakeB[i])\n",
    "\tfor i in range(n_samples):\n",
    "\t\tpyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(X_realB[i])\n",
    "\tfilename1 = 'plot_%06d.png' % (step+1)\n",
    "\tpyplot.savefig(filename1)\n",
    "\tpyplot.close()\n",
    "\tfilename2 = 'model_%06d_.h5' % (step+1)\n",
    "\tg_model.save(filename2)\n",
    "\tprint('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bebb9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n",
    "\tn_patch = d_model.output_shape[1]\n",
    "\ttrainA, trainB = dataset\n",
    "\tbat_per_epo = int(len(trainA) / n_batch)\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "\t\tg_loss, _, _= gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "\t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
    "\t\t\tsummarize_performance(i, g_model, dataset)\n",
    "\t\t\td_model.save(f\"dis{(i+1)}_new.h5\")\n",
    "\n",
    "dataset = load_real_samples('maps_256.npz')\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "image_shape = dataset[0].shape[1:]\n",
    "d_model = define_discriminator(image_shape)\n",
    "d_model.load_weights('/home/project/synthetic_learning/dis43840_new.h5')\n",
    "g_model = define_generator(image_shape)\n",
    "g_model.load_weights('/home/project/synthetic_learning/model_043840_.h5')\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "train(d_model, g_model, gan_model, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
